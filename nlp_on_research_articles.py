# -*- coding: utf-8 -*-
"""nlp-on-research-articles.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11xh3zZFwQoaTflhnD70VMiX7g5_Q5LZr
"""

import pandas as pd
df_train=pd.read_csv('/kaggle/input/janatahack-independence-day-2020-ml-hackathon/train.csv')
df_test=pd.read_csv('/kaggle/input/janatahack-independence-day-2020-ml-hackathon/test.csv')
df_test.head()

df_train.head()

import re
import spacy
import string

def clean_text(text):
    text = text.lower()

    text = re.sub(r'http\S+|www.\S+', '', text)

    allowed_punct = "-–"
    punct_to_remove = ''.join([p for p in string.punctuation if p not in allowed_punct])
    text = re.sub(rf"[{re.escape(punct_to_remove)}]", " ", text)
    text = re.sub(r'\s+', ' ', text).strip()


    return text
df_train['TITLE'] = df_train['TITLE'].apply(clean_text)
df_train['ABSTRACT'] = df_train['ABSTRACT'].apply(clean_text)

df_test['TITLE'] = df_test['TITLE'].apply(clean_text)
df_test['ABSTRACT'] = df_test['ABSTRACT'].apply(clean_text)

import spacy
from tqdm import tqdm

nlp = spacy.load("en_core_web_sm", disable=["parser", "ner", "textcat"])

def spacy_token_lemma(texts):
    lemmas_list = []
    for doc in tqdm(nlp.pipe(texts, batch_size=100, n_process=1), total=len(texts)):
        lemmas = [token.lemma_ for token in doc if token.is_alpha]
        lemmas_list.append(" ".join(lemmas))
    return lemmas_list

df_train['TITLE'] = spacy_token_lemma(df_train['TITLE'])
df_train['ABSTRACT'] = spacy_token_lemma(df_train['ABSTRACT'])

df_test['TITLE'] = spacy_token_lemma(df_test['TITLE'])
df_test['ABSTRACT'] = spacy_token_lemma(df_test['ABSTRACT'])

df_train['TEXT'] = df_train['TITLE'] + ' ' + df_train['ABSTRACT']
df_test['TEXT'] = df_test['TITLE'] + ' ' + df_test['ABSTRACT']
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=10000)
X_train = vectorizer.fit_transform(df_train['TEXT'])
X_test = vectorizer.transform(df_test['TEXT'])

target_columns = ['Computer Science', 'Physics', 'Mathematics',
                  'Statistics', 'Quantitative Biology', 'Quantitative Finance']

label_counts = df_train[target_columns].sum().sort_values(ascending=False)

print("Label counts:")
print(label_counts)

import matplotlib.pyplot as plt

label_counts.plot(kind='bar', figsize=(10, 5), title='Label Distribution')
plt.ylabel('Number of samples')
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, accuracy_score
from sklearn.multioutput import MultiOutputClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import KFold
import numpy as np

# 1. Define target columns
target_columns = ['Computer Science', 'Physics', 'Mathematics',
                  'Statistics', 'Quantitative Biology', 'Quantitative Finance']
y = df_train[target_columns]

# 2. Combine TITLE and ABSTRACT as features
X_text = df_train['TITLE'] + " " + df_train['ABSTRACT']

# 3. Vectorize the text
vectorizer = TfidfVectorizer(max_features=10000)
X = vectorizer.fit_transform(X_text)

# 4. Optional Cross-Validation (before splitting)
base_clf = LogisticRegression(max_iter=1000, class_weight='balanced')
multi_clf = MultiOutputClassifier(base_clf)

# Use stratified KFold if labels were single-label; here use KFold
cv = KFold(n_splits=5, shuffle=True, random_state=42)

print("Running 5-fold cross-validation...")
cv_scores = cross_val_score(multi_clf, X, y, cv=cv, scoring='accuracy')
print("Cross-validation accuracies:", cv_scores)
print("Mean accuracy:", np.mean(cv_scores))

# 5. Train-validation split
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42)

# 6. Train on training split
clf = MultiOutputClassifier(LogisticRegression(max_iter=1000, class_weight='balanced'))
clf.fit(X_train, y_train)

# 7. Predict
y_train_pred = clf.predict(X_train)
y_val_pred = clf.predict(X_val)

# 8. Accuracy
train_acc = accuracy_score(y_train, y_train_pred)
val_acc = accuracy_score(y_val, y_val_pred)

print("\nTrain accuracy:", train_acc)
print("Validation accuracy:", val_acc)

# 9. Classification report
print("\nClassification report on validation set:\n")
print(classification_report(y_val, y_val_pred, target_names=target_columns))

y_test_pred = clf.predict(X_test)

y_test_pred_df = pd.DataFrame(y_test_pred, columns=y_train.columns)
y_test_pred_df.head()

import joblib
joblib.dump(clf, "multilabel_logreg_model.pkl")

_test_pred_df = pd.DataFrame(y_test_pred, columns=y.columns)

y_test_pred_df.to_csv("test_predictions.csv", index=False)
print("\n✅ Predictions saved to 'test_predictions.csv'")